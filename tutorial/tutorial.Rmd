---
title: "vera4cast tutoral"
author: Freya Olsson
output:
  md_document: 
    variant: markdown_github
    number_sections: true
    toc: true
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# This VERA tutorial

This document presents a short tutorial to get you started on generating ecological forecasts specifically for submission to the Virginia Ecoforecast Reservoir Analysis (VERA) Forecast Challenge. The materials are modified from those initially developed for the EFI-NEON Forecast Challenge (found [here](https://zenodo.org/records/8316966)). To learn more about the VERA Forecast Challenge, see our [website](https://www.ltreb-reservoirs.org/vera4cast/)). 

The development of these materials has been supported by NSF grants DEB-2327030, DEB-1926388, and DBI-1933016.

To complete the tutorial via this markdown document, the following R packages will need to be installed first:

-   `remotes`
-   `tidyverse`
-   `lubridate`
-   `RopenMeteo` (from Github)
-   `vera4castHelpers` (from Github)

The following code chunk should be run to install packages.

```{r eval = F}
install.packages('remotes')
install.packages('tidyverse') # collection of R packages for data manipulation, analysis, and visualisation
install.packages('lubridate') # working with dates and times

remotes::install_github('FLARE-forecast/RopenMeteo') # R interface with API OpenMeteo - weather forecasts
remotes::install_github('LTREB-reservoirs/vera4castHelpers') # package to assist with forecast submission
```

```{r}
library(tidyverse)
library(lubridate)
```

If you do not wish to run the code yourself, you can alternatively follow along via the html (tutorial.md).

# Introduction to VERA Forecast Challenge

The VERA Forecast Challenge is hosted by the Center for Ecosystem Forecasting at Virginia Tech [CEF](https://ecoforecast.centers.vt.edu). We are using forecasts to compare the predictability of different ecosystem variables, across many different ecosystem conditions, to identify the fundamental predictability of freshwater ecosystems.

The VERA Forecast Challenge is one component of the Virginia Reservoirs LTREB project, which is both monitoring and forecasting two reservoirs with contrasting dissolved oxygen conditions in southwestern Virginia, USA to broadly advance our understanding of freshwater ecosystem predictability.

## The Challenge

What: Freshwater water quality.

Where: Two Virginia reservoirs (managed by the Western Virginia Water Authority) and the stream that connects them. To learn more about these freshwater ecosystems, see [here](https://www.ltreb-reservoirs.org/reservoirs/).

When: Daily forecasts for at least 30 days-ahead in the future. New forecast submissions that are continuously updated with observations as soon as they become available are accepted daily. The only requirement is that submissions are predictions of the future at the time the forecast is submitted.

For the VERA Challenge, you can chose to submit to any combination of sites and variables using any method. Find more information about the targets available [here](https://www.ltreb-reservoirs.org/vera4cast/targets.html).

## Submission requirements

For the VERA Challenge, submitted forecasts must include quantified uncertainty. The submitted file can represent uncertainty using an ensemble forecast (multiple realizations of future conditions) or a distribution forecast (with mean and standard deviation), specified in the family and parameter columns of the forecast file.

### File format

The file is a csv format with the following columns:

-   `project_id`: use `vera4cast`

-   `model_id`: the short name of the model defined as the `model_id` in the file name (see below) and in your registration. The `model_id` should have no spaces.

-   `datetime`: forecast timestamp. Format `%Y-%m-%d %H:%M:%S`.

-   `reference_datetime`: the start of the forecast (0 times steps into the future). There should only be one value of reference_datetime in the file. Format is `%Y-%m-%d %H:%M:%S`.

-   `duration`: the time-step of the forecast. Use the value of P1D for a daily forecast and PT1H for an hourly forecast.

-   `site_id`: code for site

-   `depth_m`: the depth (meters) for the forecasted variable.

-   `family`: name of the probability distribution that is described by the parameter values in the parameter column. For an ensemble forecast, the `family` column uses the word `ensemble` to designate that it is a ensemble forecast and the parameter column is the ensemble member number (1, 2, 3 ...). For a distribution forecast, the `family` describes the type of distribution. For a parametric forecast with the normal distribution, the `family` column uses the word `normal` to designate a normal distribution and the parameter column must have values of `mu` and `sigma` for each forecasted variable, site_id, depth and time combination.

Parametric forecasts for binary variables should use bernoulli as the distribution.

The following names and parameterization of the distribution are supported (family: parameters):

-   lognormal: mu, sigma
-   normal: mu,sigma
-   bernoulli: prob
-   beta: shape1, shape2
-   uniform: min, max
-   gamma: shape, rate
-   logistic: location, scale
-   exponential: rate
-   poisson: lambda

If you are submitting a forecast that is not in the supported list above, we recommend using the ensemble format and sampling from your distribution to generate a set of ensemble members that represents your distribution. The full list of required columns and format can be found in the [Challenge documentation](https://www.ltreb-reservoirs.org/vera4cast/instructions.html#forecast-file-format).

-   `parameter` the parameters for the distribution or the number of the ensemble members.

-   `variable`: standardized variable name

-   `prediction`: forecasted value

# The forecasting workflow

## Read in the data

We start forecasting by first looking at the historical data - called the 'targets'. These data are available in near real-time, with the latency of approximately 24-48 hrs. Here is how you read in the data from the targets file available:

```{r eval=TRUE, echo = TRUE, error=FALSE, warning=FALSE, message=FALSE}
#read in the targets data
targets <- read_csv('https://renc.osn.xsede.org/bio230121-bucket01/vera4cast/targets/project_id=vera4cast/duration=P1D/daily-insitu-targets.csv.gz')
```

Information on the VERA sites can be found in the `vera4cast_field_site_metadata.csv` file on GitHub. This table has information about the field sites, including location, reservoir depth, and surface area.

```{r eval=TRUE, echo = TRUE, error=FALSE, warning=FALSE, message=FALSE}
# read in the sites data
site_list <- read_csv("https://raw.githubusercontent.com/LTREB-reservoirs/vera4cast/main/vera4cast_field_site_metadata.csv",
                      show_col_types = FALSE)
```

Let's take a look at the targets data!

```{r eval = T, echo = F}
targets[1000:1010,]

```

The columns of the targets file show the time step (duration, P1D), the 4 character site code (`site_id`), the variable being measured, and the mean daily observation. We will start by just looking at Falling Creek Reservoir (`fcre`).

```{r}
site_list <- site_list %>%
  filter(site_id == 'fcre')

targets <- targets %>%
  filter(site_id == 'fcre')

targets |> distinct(variable)
```

There are a number of different physical, chemical, and biological variables with observations at fcre. We will start by just looking at P1D Temp_C_mean (mean daily water temperatures).

```{r}
targets <- targets %>%
  filter(variable == 'Temp_C_mean',
         duration == 'P1D')
```

## Visualise the data

```{r eval = T, echo = F, warning=FALSE, fig.dim=c(10,10), fig.cap='Figure: Temperature targets data at FCR'}
targets %>%
  filter(variable == 'Temp_C_mean') %>%
  ggplot(., aes(x = datetime, y = observation)) +
  geom_point() +
  theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  facet_wrap(~depth_m) +
  labs(title = 'water temperature')

```

We can think about what type of models might be useful to predict water temperature. Below are descriptions of three simple models to get you started forecasting:

-   We could use information about current conditions to predict the next day. What is happening today is usually a good predictor of what will happen tomorrow (baseline - persistence model).
-   We could also think about what the historical data tells us about reservoir dynamics this time of year. For example, conditions in January this year are likely to be similar to January last year (baseline - climatology/DOY model)
-   We could also look at the lake variables' relationship(s) with other variables. For example, we could use existing forecasts about the weather to generate forecasts about the reservoir variables.

To start, we will produce forecasts for just one of these depths - focal depth at fcre, 1.6 m.

```{r}
targets <- targets %>%
  filter(depth_m == 1.6)
```

# Introducing co-variates

One important step to address when thinking about generating forecasts is to include co-variates in the model. A water temperature forecast, for example, may be benefit from information about past and future weather. Data are available from OpenMeteo API, and a simple R package is available to access them. The function requires you to specify the location of the site you are interested in, the number of days into the past and future, and the model you want to use to forecast.

Read more about what variables are available and how to use the R functions [here](https://github.com/FLARE-forecast/RopenMeteo)

## Download co-variates

### Download historic data

We will generate a water temperature forecast using `air_temperature` as a co-variate. We can get the location of FCR from the `site_list` table. The maximum number of past days available from OpenMeteo API is \~90 days. If you need more historical days for model calibration and testing, historical data are available through OpenMeteo's [historical weather API](https://open-meteo.com/en/docs/historical-weather-api). The past data are a stacked 1 day-ahead pseudo-observation.

The package also includes a function to convert to EFI standard format.

```{r, message=FALSE}

lat <- site_list |>
  filter(site_id == 'fcre') |>
  select(latitude) |> 
  pull()

long <-  site_list |>
  filter(site_id == 'fcre') |>
  select(longitude) |>  
  pull()

weather_dat <- RopenMeteo::get_ensemble_forecast(
  latitude = lat,
  longitude = long,
  forecast_days = 30, # days into the future
  past_days = 60, # past days that can be used for model fitting
  model = "gfs_seamless", # this is the NOAA GEFS ensemble model
  variables = c("temperature_2m")) |>
  
  # function to convert to EFI standard
  RopenMeteo::convert_to_efi_standard() |>
  mutate(site_id = 'fcre')

```

This is an ensemble hourly forecast (multiple (31) realisations of conditions). Now we have a timeseries of historic data and a 31 member ensemble forecast of future air temperatures.

```{r echo = F, fig.cap = c('Figure: historic and future NOAA air temeprature forecasts at lake sites', 'Figure: last two months of historic air temperature forecasts and 35 day ahead forecast')}
ggplot(weather_dat, aes(x=datetime, y=prediction)) +
  geom_line(aes(group = parameter), alpha = 0.4)+
  facet_wrap(~variable, scales = 'free')
```

To generate a daily water temperature forecast, we will use a daily water temperature to train and run our model. This is calculated from the hourly data we have but retains the ensemble members as a source of driver uncertainty.

```{r}
# get daily means
daily_weather <- weather_dat |> 
  mutate(datetime = as_date(datetime)) |>
  group_by(datetime, site_id, variable, parameter) |>
  summarise(prediction = mean(prediction))
```

We will separate the data into `historic_weather` for training/calibration and then `future_weather` to generate a forecast. We will also convert to Celsius from Kelvin. For the historical data we do not need the individual ensemble members, and will train with the ensemble mean.

```{r}
# split it into historic and future
forecast_date <- Sys.Date()
historic_weather <- daily_weather |>
  filter(datetime < forecast_date) |>
  group_by(datetime, variable, site_id) |> 
  # calculate the ensemble mean
  summarise(prediction = mean(prediction)) |> 
  pivot_wider(names_from = variable, values_from = prediction) |>
  mutate(air_temperature = air_temperature - 273.15) # convert to degree C


future_weather <- daily_weather |>
  filter(datetime >= forecast_date) |>
  pivot_wider(names_from = variable, values_from = prediction) |>
  mutate(air_temperature = air_temperature - 273.15) # convert to degree C

```

# Linear model with co-variates

We will fit a simple linear model between historical air temperature and the water temperature targets data. Using this model we can then use our future forecasts of air temperature (all 31 ensembles from NOAA GEFS) to estimate water temperature at each site. The ensemble weather forecast will therefore propagate uncertainty into the water temperature forecast and give an estimate of driving data uncertainty.

We will start by joining the historic weather data with the targets to aid in fitting the linear model.

```{r}
targets_lm <- targets |> 
  pivot_wider(names_from = 'variable', values_from = 'observation') |> 
  left_join(historic_weather, 
            by = c("datetime","site_id"))

tail(targets_lm)
```

To fit the linear model, we use the base R `lm()` but there are also methods to fit linear (and non-linear) models in the `fable::` package. You can explore the [documentation](https://otexts.com/fpp3/regression.html) for more information on the `fable::TSLM()` function.

```{r}

# Fit linear model based on past data: water temperature = m * air temperature + b
fit <- lm(targets_lm$Temp_C_mean ~ targets_lm$air_temperature)
    
# Use the fitted linear model to forecast water temperature for each ensemble member
forecasted_temperature <- fit$coefficients[1] + fit$coefficients[2] * future_weather$air_temperature

# Put all the relevant information into a tibble that we can bind together
temp_lm_forecast <- tibble(datetime = future_weather$datetime,
                           site_id = future_weather$site_id,
                           parameter = future_weather$parameter,
                           prediction = forecasted_temperature,
                           variable = "Temp_C_mean")
  
```

We now have 31 possible forecasts of water temperature at each site and each day. On this plot each line represents one of the possible forecasts and the range of forecasted water temperature is a simple quantification of the uncertainty in our forecast.

Looking at the forecasts we produced:

```{r, echo = F, warning = F}
temp_lm_forecast %>% 
  filter(variable == 'Temp_C_mean') %>%
  ggplot(.,aes(x=datetime, y=prediction, group = parameter)) + 
  geom_point(data = filter(targets, depth_m == 1.6), 
             aes(x=as_date(datetime), y=observation, group = 'obs'), colour = 'darkblue') +
  geom_line(alpha = 0.3, aes(colour = 'ensemble member (parameter)')) + 
  facet_wrap(~site_id, scales = 'free_y') +
  scale_x_date(expand = c(0,0), date_labels = "%d %b") +
  labs(y = 'value') +
  geom_vline(aes(linetype = 'reference_datetime', xintercept = Sys.Date()), colour = 'blue', size = 1.5) +
  labs(title = 'site_id', subtitle = 'variable = temperature', caption = 'prediction') + 
  annotate("text", x = forecast_date - days(10), y = 20, label = "past")  +
  annotate("text", x = forecast_date + days(12), y = 20, label = "future")  +
  theme_bw() +
  coord_cartesian(xlim = c(min(temp_lm_forecast$datetime) - 15,
                           forecast_date + 30)) +
  scale_linetype_manual(values = 'dashed', name = '') +
  scale_colour_manual(values = 'darkgrey', name = '') 
```

## Convert to forecast standard for submission

A reminder of the columns needed for an ensemble forecast:

-   `datetime`: forecast timestamp for each time step
-   `reference_datetime`: The start of the forecast
-   `site_id`: code for site
-   `family`: describes how the uncertainty is represented
-   `parameter`: integer value for forecast replicate
-   `variable`: standardized variable name
-   `prediction`: forecasted value
-   `model_id`: model name (no spaces) - including `example` will ensure we don't need to register!

The columns `project_id`, `depth_m`, and `duration` are also needed. For a daily forecast the duration is `P1D`. We produced a water temperature forecast at the focal depth only (1.6 m).

```{r}
# Remember to change the model_id when you make changes to the model structure!
model_id <- 'example_ID'

temp_lm_forecast_standard <- temp_lm_forecast %>%
  mutate(model_id = model_id,
         reference_datetime = forecast_date,
         family = 'ensemble',
         parameter = as.character(parameter),
         duration = 'P1D', 
         depth_m = 1.6,
         project_id = 'vera4cast') %>%
  select(datetime, reference_datetime, site_id, duration, family, parameter, variable, prediction, depth_m, model_id, project_id)
```

## Submit forecast

Files need to be in the correct format for submission. The forecast organizers have created tools to help aid in the submission process. These tools can be downloaded from Github using `remotes::install_github('LTREB-reservoirs/vera4castHelpers')`. These include functions for submitting, scoring, and reading forecasts:

-   `submit()` - submit the forecast file to the VERA Challenge, where it will be scored
-   `forecast_output_validator()` - check the file is in the correct format to be submitted

```{r eval = T}
# Start by writing the forecast to file
save_here <- 'Forecasts/' # just for helpful organisation
forecast_file <- paste0(save_here, forecast_date, '-', model_id, '.csv')

if (dir.exists(save_here)) {
  write_csv(temp_lm_forecast_standard, forecast_file)
} else {
  dir.create(save_here)
  write_csv(temp_lm_forecast_standard, forecast_file)
}

```

```{r eval = FALSE, echo = T}
vera4castHelpers::submit(forecast_file = forecast_file)
```

Is the linear model a reasonable relationship between air temperature and water temperature? Would a non-linear relationship be better? What about using yesterday's air and water temperatures to predict tomorrow? Or including additional parameters? There's a lot of variability in water temperatures unexplained by air temperature alone.

```{r, echo=F, warning=F}
ggplot(targets_lm, aes(x=air_temperature, y= Temp_C_mean, colour = site_id)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = 'lm') +
  theme_bw()
```

## TASKS

Possible modifications to the simple linear model:

-   Include additional weather co-variates in the linear model. List them in the `get_ensemble_forecast()` function
-   Specify a non-linear relationship
-   Try forecasting another variable - could you use your water temperature to estimate dissolved oxygen concentration at the surface? To learn more about the other focal variables, see [here](https://www.ltreb-reservoirs.org/vera4cast/targets.html)
-   Include a lag in the predictors
-   Add another source of uncertainty - what are the errors in the linear model?

Until you start submitting 'real' forecasts you can (should) keep `example` in the model_id. These forecasts are processed and scored but are not retained for longer than 1 month.

## Register your participation

It's really important that once you start submitting forecasts to the Challenge that you register your participation. You will not be able to submit a forecast that is not an example, without first registering the model_id, with associated metadata. You should register [here](https://forms.gle/kg2Vkpho9BoMXSy57).

Read more on the VERA Forecast Challenge website <https://www.ltreb-reservoirs.org/vera4cast/instructions.html>.
